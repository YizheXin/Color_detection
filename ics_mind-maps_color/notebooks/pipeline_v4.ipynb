{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ce31844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "from matplotlib.patches import Rectangle\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee135bb8",
   "metadata": {},
   "source": [
    "### One function for each step in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb3d1da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ocr_data(json_file):\n",
    "    with open(json_file) as fp:\n",
    "        data = json.loads(fp.read())\n",
    "    \n",
    "    nodes = []\n",
    "    chars_to_filter = ['i', 't', 'l', 'x', 'y','o']\n",
    "\n",
    "    for b in data['Blocks']:\n",
    "        if b['BlockType'] == 'LINE' and (len(b['Text']) > 1 or b['Text'].lower() not in chars_to_filter):\n",
    "            node = {'text': b['Text'], \n",
    "                    'left': b['Geometry']['BoundingBox']['Left'], \n",
    "                    'top': b['Geometry']['BoundingBox']['Top'],\n",
    "                    'right': b['Geometry']['BoundingBox']['Left'] + b['Geometry']['BoundingBox']['Width'],\n",
    "                    'bottom': b['Geometry']['BoundingBox']['Top'] + b['Geometry']['BoundingBox']['Height']}\n",
    "\n",
    "            nodes.append(node)\n",
    "    \n",
    "    return pd.DataFrame(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf03d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_image(filename):\n",
    "    \n",
    "    img = cv2.imread(filename)\n",
    "    \n",
    "    return cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb43c3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_image(image, threshold_value = 200):\n",
    "    \n",
    "    img = image.copy()\n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, threshold = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    threshold = 1 - (threshold / 255.)\n",
    "    \n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad2c2783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_bounding_boxes_in_pixels(df, img):\n",
    "    \n",
    "    img_height = img.shape[0]\n",
    "    img_width = img.shape[1]\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "         \n",
    "        df.at[i, 'left']   = int(round(row['left'] * img_width))\n",
    "        df.at[i, 'right']  = int(round(row['right'] * img_width))\n",
    "        df.at[i, 'top']    = int(round(row['top'] * img_height))\n",
    "        df.at[i, 'bottom'] = int(round(row['bottom'] * img_height))\n",
    "        \n",
    "    df['left']   = df['left'].astype(int)\n",
    "    df['right']  = df['right'].astype(int)\n",
    "    df['top']    = df['top'].astype(int)\n",
    "    df['bottom'] = df['bottom'].astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ddd12784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_font_size(df):\n",
    "    \n",
    "    df['font_size'] = df.bottom - df.top\n",
    "    \n",
    "    df['font_size'] = (df['font_size'] - df['font_size'].mean()) / (df['font_size'].std() + 1e-6)\n",
    "    \n",
    "    df['font_size'] = (df['font_size'].apply(lambda x: round(x)) + 10).astype(int)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd75b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_shape_gaps5(image, ocr,\n",
    "                      dist_threshold_percent = 30, \n",
    "                      activation_lower_th = 40, \n",
    "                      activation_upper_th = 70):\n",
    "\n",
    "    img = image.copy()\n",
    "    img = (1-img) * 10\n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    kernel[1,1] = 10\n",
    "\n",
    "    dst = cv2.filter2D(img,-1,kernel).astype(int)\n",
    "\n",
    "    points_thr = np.where((dst > activation_lower_th) & (dst < activation_upper_th))\n",
    "\n",
    "    points = []\n",
    "    for p_i in range(len(points_thr[0])): \n",
    "        points.append([points_thr[0][p_i], points_thr[1][p_i]])\n",
    "\n",
    "    points = np.stack(points, axis=0)\n",
    "\n",
    "    nodes_points = []\n",
    "\n",
    "    nodes_points.extend([[row.top, row.left] for i, row in ocr.iterrows()])\n",
    "    nodes_points.extend([[row.top, row.right] for i, row in ocr.iterrows()])\n",
    "    nodes_points.extend([[row.bottom, row.right] for i, row in ocr.iterrows()])\n",
    "    nodes_points.extend([[row.bottom, row.left] for i, row in ocr.iterrows()])\n",
    "\n",
    "    nodes_points   = np.array(nodes_points)\n",
    "    dist_matrix    = euclidean_distances(points)\n",
    "    max_bb_height  = (ocr.bottom - ocr.top).max()\n",
    "    dist_threshold = int((max_bb_height * dist_threshold_percent)/100)\n",
    "\n",
    "    below_th = np.where((dist_matrix < dist_threshold) & (dist_matrix > 0)) # zero is trivial distance, no need to fill any gap\n",
    "\n",
    "    img_out = image.copy()\n",
    "\n",
    "    for i in range(len(below_th[0])):\n",
    "\n",
    "        p1 = points[below_th[0][i]]\n",
    "        p2 = points[below_th[1][i]]\n",
    "\n",
    "        dist_to_nodes = euclidean_distances(np.stack([p1, p2]), nodes_points)\n",
    "        closest_node = np.argmin(dist_to_nodes) % len(ocr)\n",
    "\n",
    "        closest_node_height = ocr.loc[closest_node, 'bottom'] - ocr.loc[closest_node, 'top']\n",
    "\n",
    "        dist_threshold = int((closest_node_height * dist_threshold_percent)/100)\n",
    "\n",
    "        if np.linalg.norm(p2-p1) < dist_threshold:\n",
    "\n",
    "\n",
    "            cv2.line(img_out, [p1[1],p1[0]], [p2[1],p2[0]],  (1, 1, 1), thickness=1)\n",
    "    \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3e1ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stamp_bounding_boxes_on_image(df, img, erotion_percent = 10):\n",
    "    \n",
    "    img_out = img.copy()\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        \n",
    "        width = row['right'] - row['left']\n",
    "        erotion_width = int(round((width * erotion_percent) / 100))\n",
    "        \n",
    "        height = row['bottom'] - row['top']\n",
    "        erotion_height = int(round((height * erotion_percent) / 100))\n",
    "        \n",
    "\n",
    "        img_out[ (row['top'] + erotion_height)  : (row['bottom'] - erotion_height), \n",
    "                 (row['left'] + erotion_width) : (row['right'] - erotion_width) ] = 1\n",
    "    \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e276b4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filled_shapes(img):\n",
    "    \n",
    "    contours, tree = cv2.findContours(cv2.convertScaleAbs(img), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    img_out = np.zeros_like(img)\n",
    "\n",
    "    for i, contour in enumerate(contours):\n",
    "        cv2.drawContours(img_out, [contour], 0, (1, 1, 1), thickness=cv2.FILLED)\n",
    "        \n",
    "    return img_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "319f5bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks(img, max_iter=10):\n",
    "    \n",
    "\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "\n",
    "    img_eroded = [img.copy()]\n",
    "    contours_iter = []\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        contours, tree = cv2.findContours(cv2.convertScaleAbs(img_eroded[-1]), \n",
    "                                          cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        contours_iter.append(contours)\n",
    "        img_eroded.append(cv2.erode(img_eroded[-1], kernel, iterations = 1))\n",
    "    \n",
    "    min_contours = len(contours_iter[-1])\n",
    "    min_contours_iteration = len(contours_iter)-1\n",
    "\n",
    "    for i in range(len(contours_iter)-1, -1, -1):\n",
    "        if len(contours_iter[i]) > min_contours:\n",
    "            min_contours_iteration = i+1\n",
    "            break\n",
    "            \n",
    "            \n",
    "    nodes_mask = img_eroded[min_contours_iteration]\n",
    "    \n",
    "    nodes_mask_dilated = cv2.dilate(nodes_mask, kernel, iterations=min_contours_iteration+1)\n",
    "    edges_mask = np.maximum((img_eroded[0] - nodes_mask_dilated), 0)\n",
    "\n",
    "\n",
    "    return nodes_mask, edges_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d4c51bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edges(edges_mask):\n",
    "    \n",
    "    final_edges = []\n",
    "\n",
    "    contours, tree = cv2.findContours(cv2.convertScaleAbs(edges_mask), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for contour in contours:\n",
    "\n",
    "        countour_points = contour[:,0,:]\n",
    "\n",
    "        x_min = np.min(countour_points[:,0])\n",
    "        x_max = np.max(countour_points[:,0])\n",
    "        y_min = np.min(countour_points[:,1])\n",
    "        y_max = np.max(countour_points[:,1])\n",
    "\n",
    "        candidates = np.array([[x_min, y_min], [x_max, y_min], [x_max, y_max], [x_min, y_max]])\n",
    "\n",
    "        minimum_distances_to_candidates = np.min(euclidean_distances(candidates, countour_points), axis=1)\n",
    "\n",
    "        final_endpoints = candidates[np.argsort(minimum_distances_to_candidates)[:4], :]\n",
    "        \n",
    "        \n",
    "        if np.linalg.norm(final_endpoints[0] - final_endpoints[1]) * 2 < np.linalg.norm(final_endpoints[0] - final_endpoints[2]):\n",
    "    \n",
    "            final_endpoints = np.array([final_endpoints[0], final_endpoints[2]])\n",
    "\n",
    "        else:\n",
    "            final_endpoints = final_endpoints[0:2]\n",
    "\n",
    "        final_edges.append(final_endpoints)\n",
    "\n",
    "\n",
    "    return np.stack(final_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b933c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_connections(edges, nodes_mask, dist_threshold_percentage = 2):\n",
    "    \n",
    "    connections = []\n",
    "    \n",
    "    dist_threshold_in_pixels = int((dist_threshold_percentage / 100) * nodes_mask.shape[0])\n",
    "    \n",
    "    nodes_contours, tree = cv2.findContours(cv2.convertScaleAbs(nodes_mask), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    for edge in edges:\n",
    "\n",
    "        connection = [None, None]\n",
    "\n",
    "        for i_endpoint, endpoint in enumerate(edge):\n",
    "\n",
    "            endpoint = np.expand_dims(endpoint, axis=0)\n",
    "\n",
    "            min_dist_to_node = 9e3\n",
    "            min_dist_node_n = -1\n",
    "\n",
    "            for i_node, node in enumerate(nodes_contours):\n",
    "\n",
    "                node = node[:,0,:]\n",
    "\n",
    "                min_dist = np.min(euclidean_distances(node, endpoint).squeeze())\n",
    "\n",
    "                if min_dist < min_dist_to_node:\n",
    "                    min_dist_to_node = min_dist\n",
    "                    min_dist_node_n = i_node\n",
    "\n",
    "            if min_dist_to_node < dist_threshold_in_pixels:\n",
    "\n",
    "                connection[i_endpoint] = min_dist_node_n\n",
    "\n",
    "        if connection[0] is not None and connection[1] is not None and connection[0] != connection[1]:\n",
    "            connections.append(connection) \n",
    "    \n",
    "    return pd.DataFrame(connections, columns=['node a', 'node b'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8da8a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nodes(ocr, nodes_mask, threshold_iou = 0.8):\n",
    "    \n",
    "    df = ocr.copy()\n",
    "    nodes_contours, tree = cv2.findContours(cv2.convertScaleAbs(nodes_mask), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "\n",
    "        area = (row['right'] - row['left']) * (row['bottom'] - row['top'])\n",
    "\n",
    "        max_iou = 0\n",
    "        max_iou_i_node = -1\n",
    "        \n",
    "\n",
    "        for i_node, contour in enumerate(nodes_contours):\n",
    "\n",
    "            empty_img = np.zeros_like(nodes_mask)\n",
    "\n",
    "            cv2.drawContours(empty_img, [contour], 0, (1, 1, 1), thickness=-1)\n",
    "\n",
    "            intersection = empty_img[row['top']:row['bottom'], row['left']:row['right']].sum()\n",
    "\n",
    "            iou = intersection / area\n",
    "\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                max_iou_i_node = i_node\n",
    "\n",
    "        if max_iou > threshold_iou:\n",
    "\n",
    "            df.at[i, 'node_id'] = max_iou_i_node\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e83b7",
   "metadata": {},
   "source": [
    "# Real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94482984",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = ['erythrocytes L1 .jpg']\n",
    "\n",
    "ocrs = [ 'erythrocytes L1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57f98b5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'thickness' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 19\u001b[0m\n\u001b[0;32m     16\u001b[0m ocr \u001b[38;5;241m=\u001b[39m get_font_size(ocr)\n\u001b[0;32m     18\u001b[0m image\u001b[38;5;241m.\u001b[39mappend(stamp_bounding_boxes_on_image(ocr, image[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m5\u001b[39m))\n\u001b[1;32m---> 19\u001b[0m image\u001b[38;5;241m.\u001b[39mappend(\u001b[43mclose_shape_gaps5\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mocr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdist_threshold_percent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     20\u001b[0m image\u001b[38;5;241m.\u001b[39mappend(get_filled_shapes(image[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n\u001b[0;32m     22\u001b[0m proc_images\u001b[38;5;241m.\u001b[39mappend(image)\n",
      "Cell \u001b[1;32mIn[28], line 52\u001b[0m, in \u001b[0;36mclose_shape_gaps5\u001b[1;34m(image, ocr, dist_threshold_percent, activation_lower_th, activation_upper_th)\u001b[0m\n\u001b[0;32m     48\u001b[0m     dist_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((closest_node_height \u001b[38;5;241m*\u001b[39m dist_threshold_percent)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mnorm(p2\u001b[38;5;241m-\u001b[39mp1) \u001b[38;5;241m<\u001b[39m dist_threshold:\n\u001b[1;32m---> 52\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[43mthickness\u001b[49m)\n\u001b[0;32m     54\u001b[0m         cv2\u001b[38;5;241m.\u001b[39mline(img_out, [p1[\u001b[38;5;241m1\u001b[39m],p1[\u001b[38;5;241m0\u001b[39m]], [p2[\u001b[38;5;241m1\u001b[39m],p2[\u001b[38;5;241m0\u001b[39m]],  (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), thickness\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m img_out\n",
      "\u001b[1;31mNameError\u001b[0m: name 'thickness' is not defined"
     ]
    }
   ],
   "source": [
    "n_images = len(images)\n",
    "\n",
    "proc_images = []\n",
    "proc_ocrs = []\n",
    "\n",
    "for index in range(n_images):\n",
    "\n",
    "    ocr = get_ocr_data(f'../textract_outputs/{ocrs[index]}/analyzeDocResponse.json')\n",
    "\n",
    "    image = []\n",
    "\n",
    "    image.append(open_image(f'../graphs/{images[index]}'))\n",
    "    image.append(threshold_image(image[-1], threshold_value=200))\n",
    "\n",
    "    ocr = set_bounding_boxes_in_pixels(ocr, image[-1])\n",
    "    ocr = get_font_size(ocr)\n",
    "\n",
    "    image.append(stamp_bounding_boxes_on_image(ocr, image[-1], 5))\n",
    "    image.append(close_shape_gaps5(image[-1], ocr, dist_threshold_percent = 30))\n",
    "    image.append(get_filled_shapes(image[-1]))\n",
    "    \n",
    "    proc_images.append(image)\n",
    "    proc_ocrs.append(ocr)\n",
    "\n",
    "\n",
    "n_steps = len(image)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(n_images, n_steps, figsize=(5*n_steps, 5*n_images))\n",
    "\n",
    "for i in range(n_images):\n",
    "    for j in range(n_steps):\n",
    "        ax[i, j].imshow(proc_images[i][j], cmap='gray')\n",
    "        ax[i, j].set_title(f'step {j+1}')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f7c844",
   "metadata": {},
   "source": [
    "## Font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "174bb08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "\n",
    "for ocr in proc_ocrs:\n",
    "    display(ocr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1f056c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
